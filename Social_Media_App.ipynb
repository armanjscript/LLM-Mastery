{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Y6_5fp7PtMCi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5331ba3d-33da-4098-c6ef-fa961de9ff9e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/2.5 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/2.5 MB\u001b[0m \u001b[31m33.4 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m52.4 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m34.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/41.7 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.7/41.7 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/50.8 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.8/50.8 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "# Step 1: Install required libraries\n",
        "!pip install -q langchain langchain-community langchain-google-genai google-generativeai"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q streamlit"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4H8E1p3KnbXw",
        "outputId": "faf9661a-bd31-453c-8cdc-e390a7092424"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.3/44.3 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.1/9.1 MB\u001b[0m \u001b[31m47.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m56.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.1/79.1 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!npm install -q localtunnel"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GR79Rbe1nccf",
        "outputId": "f89c0278-9358-410c-9c4a-5bc2f6aeee6e"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1G\u001b[0K⠙\u001b[1G\u001b[0K⠹\u001b[1G\u001b[0K⠸\u001b[1G\u001b[0K⠼\u001b[1G\u001b[0K⠴\u001b[1G\u001b[0K⠦\u001b[1G\u001b[0K⠧\u001b[1G\u001b[0K⠇\u001b[1G\u001b[0K⠏\u001b[1G\u001b[0K⠋\u001b[1G\u001b[0K⠙\u001b[1G\u001b[0K⠹\u001b[1G\u001b[0K⠸\u001b[1G\u001b[0K⠼\u001b[1G\u001b[0K⠴\u001b[1G\u001b[0K⠦\u001b[1G\u001b[0K⠧\u001b[1G\u001b[0K⠇\u001b[1G\u001b[0K⠏\u001b[1G\u001b[0K⠋\u001b[1G\u001b[0K⠙\u001b[1G\u001b[0K⠹\u001b[1G\u001b[0K⠸\u001b[1G\u001b[0K\n",
            "added 22 packages in 3s\n",
            "\u001b[1G\u001b[0K⠸\u001b[1G\u001b[0K\n",
            "\u001b[1G\u001b[0K⠸\u001b[1G\u001b[0K3 packages are looking for funding\n",
            "\u001b[1G\u001b[0K⠸\u001b[1G\u001b[0K  run `npm fund` for details\n",
            "\u001b[1G\u001b[0K⠸\u001b[1G\u001b[0K"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q python-dotenv"
      ],
      "metadata": {
        "id": "_slq5F84viN5"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile .env\n",
        "GOOGLE_API_KEY=\"YOUR_GOOGLE_API_KEY\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8BfRJcCXAMEj",
        "outputId": "30460a84-f0df-4842-b4e4-4476c12f19a2"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing .env\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile Social_Media_App.py\n",
        "import streamlit as st\n",
        "from dotenv import load_dotenv\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "from langchain_core.prompts import (\n",
        "    SystemMessagePromptTemplate,\n",
        "    HumanMessagePromptTemplate,\n",
        "    ChatPromptTemplate,\n",
        "    PromptTemplate\n",
        ")\n",
        "\n",
        "load_dotenv()\n",
        "\n",
        "def initialize_model(temperature, model_name):\n",
        "  return ChatGoogleGenerativeAI(temperature=temperature, model=model_name)\n",
        "\n",
        "def create_chat_template():\n",
        "  system_prompt_template = PromptTemplate(\n",
        "      template = \"You are expert in generating script for social media.\"\n",
        "  )\n",
        "\n",
        "  system_message_template = SystemMessagePromptTemplate(prompt=system_prompt_template)\n",
        "\n",
        "  user_prompt_template = PromptTemplate(\n",
        "      template = \"\"\"Write a {format} script for {content_type} about {topic}.\n",
        "                    The category of the topic is {category}, the target {audience},\n",
        "                    and the duration is {duration} seconds. Generate an approptiate title as well for the generated content.\"\"\",\n",
        "      input_variables=[\"content_type\", \"topic\", \"category\", \"audience\", \"format\", \"duration\"]\n",
        "  )\n",
        "\n",
        "  user_message_template = HumanMessagePromptTemplate(prompt=user_prompt_template)\n",
        "\n",
        "  chat_prompt_template = ChatPromptTemplate.from_messages([\n",
        "      system_message_template,\n",
        "      user_message_template\n",
        "  ])\n",
        "\n",
        "  return chat_prompt_template\n",
        "\n",
        "\n",
        "def generate_response(model, parser, chat_template, **parameters):\n",
        "  messages = chat_template.format_messages(**parameters)\n",
        "  response = model.invoke(messages)\n",
        "  return parser.invoke(response)\n",
        "\n",
        "\n",
        "def main():\n",
        "  st.title(\"Social Media Script Generator\")\n",
        "  st.write(\"This app generates scripts for social media content using gemini-1.5-pro\")\n",
        "\n",
        "\n",
        "  st.sidebar.title(\"Model Configuration\")\n",
        "  temperature = st.sidebar.slider(\"Temperature\", min_value=0.0, max_value=1.0, step=0.1)\n",
        "  model_name = st.sidebar.selectbox(\"Select Model\", [\"gemini-1.5-pro\"])\n",
        "\n",
        "  chat_model = initialize_model(temperature, model_name)\n",
        "  parser = StrOutputParser()\n",
        "  chat_template = create_chat_template()\n",
        "\n",
        "  content_type = st.selectbox(\"Select Content Type\", [\"Youtube\", \"Instagram\"]).lower()\n",
        "  topic = st.text_input(\"Enter The Topic for the Script\")\n",
        "  category = st.selectbox(\"Select The Category Of The Script\", [\"Fashion\", \"Education\", \"Technology\", \"Health\", \"Travel\"])\n",
        "\n",
        "  audience = st.multiselect(\"Select the Target Audience\" , [\"Students\", \"Housewives\", \"Professionals\", \"Teenagers\", \"Seniors\"])\n",
        "\n",
        "  format = st.selectbox(\"Select Format\", [\"Reel\", \"Video\"])\n",
        "  duration = st.slider(\"Select The Duration Of The Script in Seconds\", min_value=15, max_value=300, step=5)\n",
        "\n",
        "  if st.button(\"Generate Script\"):\n",
        "    if content_type and topic and category and audience and format and duration:\n",
        "      with st.status(\"Generating the response...\"):\n",
        "        response = generate_response(\n",
        "            model = chat_model,\n",
        "            parser=parser,\n",
        "            chat_template=chat_template,\n",
        "            content_type=content_type,\n",
        "            topic=topic,\n",
        "            category=category,\n",
        "            audience=', '.join(audience),\n",
        "            format=format,\n",
        "            duration=duration\n",
        "        )\n",
        "\n",
        "        st.success(\"Script generated successfully!!\")\n",
        "        st.subheader(\"Generated Script\")\n",
        "        st.write(response)\n",
        "    else:\n",
        "      st.warning(\"Please fill in all the fields.\")\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "  main()"
      ],
      "metadata": {
        "id": "KRNE3ImrJPwS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3a838b0c-9418-4f23-f569-c290570acb0c"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing Social_Media_App.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!streamlit run Social_Media_App.py &>/content/logs.txt &"
      ],
      "metadata": {
        "id": "DcNHGa4k5AiL"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!wget -q -O - ipv4.icanhazip.com"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zgQ8iWxT5NjE",
        "outputId": "b408d103-4b2f-4998-b414-9621279541ea"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "34.125.172.74\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!npx localtunnel --port 8501"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TZiQFOzw5OWD",
        "outputId": "43ac505f-fa6b-4010-f26b-09bcac2568d0"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1G\u001b[0K⠙\u001b[1G\u001b[0Kyour url is: https://gentle-waves-swim.loca.lt\n",
            "^C\n"
          ]
        }
      ]
    }
  ]
}