{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Y6_5fp7PtMCi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c7fe41e4-a792-45da-e507-d8a52a6d6a53"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/2.5 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m106.4 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m48.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/41.7 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.7/41.7 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/50.8 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.8/50.8 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install -q langchain langchain-community langchain-google-genai google-generativeai pydantic"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.prompts import (\n",
        "    PromptTemplate,\n",
        "    ChatPromptTemplate,\n",
        "    HumanMessagePromptTemplate,\n",
        "    SystemMessagePromptTemplate\n",
        ")\n",
        "from langchain_core.messages import SystemMessage\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "from langchain_core.output_parsers.pydantic import PydanticOutputParser\n",
        "from pydantic import BaseModel, Field\n",
        "import os\n",
        "import getpass\n",
        "import json"
      ],
      "metadata": {
        "id": "wAQnZKBBUCOA"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if \"GOOGLE_API_KEY\" not in os.environ:\n",
        "    os.environ[\"GOOGLE_API_KEY\"] = getpass.getpass(\"Enter your GOOGLE API Key: \")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vmRTz1ITUMlg",
        "outputId": "54ef712e-0a58-488a-b69a-391e58a91ab1"
      },
      "execution_count": 3,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter your GOOGLE API Key: ··········\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = ChatGoogleGenerativeAI(model=\"gemini-1.5-pro\")  # Use 'gemini-pro' as the model"
      ],
      "metadata": {
        "id": "CB_o-GRkT5q0"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "user_prompt_template = PromptTemplate(\n",
        "    template = \"\"\"\n",
        "    Topic: {topic}\n",
        "    Content: This is a content for the above topic:\n",
        "    \"\"\",\n",
        "    input_variables = [\"topic\"]\n",
        ")\n",
        "\n",
        "user_message_template = HumanMessagePromptTemplate(prompt=user_prompt_template)"
      ],
      "metadata": {
        "id": "KRNE3ImrJPwS"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "content_chat_prompt_template = ChatPromptTemplate([\n",
        "    SystemMessage(content=\"You are a content creator. Given the topic, it is your job to write short Instagram reel content, which can be spoken in 30 seconds.\"),\n",
        "    user_message_template\n",
        "])"
      ],
      "metadata": {
        "id": "PP1UQBppSeWk"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "content_chain = content_chat_prompt_template | model | StrOutputParser()"
      ],
      "metadata": {
        "id": "EWY1X-mPTnIS"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hashtag_prompt_template = PromptTemplate(\n",
        "    template = \"\"\"\n",
        "    Content:\n",
        "    {content}\n",
        "    Generate Hash tags for the above content:\n",
        "    \"\"\",\n",
        "    input_varaiables = [\"cotent\"]\n",
        ")\n",
        "\n",
        "hashtag_message_template = HumanMessagePromptTemplate(prompt=hashtag_prompt_template)"
      ],
      "metadata": {
        "id": "mU_gTkZKUREr"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ContentOutputStructure(BaseModel):\n",
        "  content: str = Field(description=\"Generated content\")\n",
        "  hashtags: str = Field(description=\"Generated hashtags\")\n",
        "\n",
        "parser = PydanticOutputParser(pydantic_object=ContentOutputStructure)"
      ],
      "metadata": {
        "id": "xLDC2zZHVeG0"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hashtag_system_prompt_template = PromptTemplate(\n",
        "    template= \"\"\"\\n{format_instructions}\\n You are a content creator. Given the content, it is your job to write hashtags for instagram reels.\"\"\",\n",
        "    partial_variables={\"format_instructions\": parser.get_format_instructions()},\n",
        ")\n",
        "\n",
        "hashtag_system_message_template = SystemMessagePromptTemplate(prompt=hashtag_system_prompt_template)"
      ],
      "metadata": {
        "id": "5a9PvSFYW8tD"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hashtag_chat_prompt_template = ChatPromptTemplate.from_messages([\n",
        "    hashtag_system_message_template,\n",
        "    user_message_template\n",
        "])"
      ],
      "metadata": {
        "id": "HEzT614ZYNEM"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hashtags_chain = hashtag_chat_prompt_template | model | parser"
      ],
      "metadata": {
        "id": "Ph_3vdZHYvc8"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "overall_chain = content_chain | hashtags_chain"
      ],
      "metadata": {
        "id": "ch4OWakvY-67"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response = overall_chain.invoke({\"topic\": \"Greatest snipers of all time\"})"
      ],
      "metadata": {
        "id": "-K6T6iUFZeCE"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "json_output = response.json()\n",
        "output_dict = json.loads(json_output)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_vGvOfH6Zahc",
        "outputId": "7961e439-ec39-4712-d0d7-7acb13f5de9a"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-17-e87feca780c5>:1: PydanticDeprecatedSince20: The `json` method is deprecated; use `model_dump_json` instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.10/migration/\n",
            "  json_output = response.json()\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"JSON response: {output_dict}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9ajS-ejIZ6ut",
        "outputId": "ec73bbe8-ac56-465c-8086-96ea28878171"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "JSON response: {'content': 'Dive into the world of legendary snipers! From Simo Häyhä, the White Death, to Chris Kyle, the American Sniper, discover the stories behind these masters of precision and camouflage.  Who do YOU think is the greatest sniper of all time? Let us know in the comments!', 'hashtags': '#sniper #history #military #sharpshooter #marksman #legend #ww2 #warfare #covertwarfare #longrangeshooting #guns #rifle #precision #camouflage #simohayha #lyudmilapavlichenko #carloshathcock #chriskyle #americansniper #ladydeath #whitedeath #whitefeather #greatestsniper #top5 #commentbelow'}\n"
          ]
        }
      ]
    }
  ]
}