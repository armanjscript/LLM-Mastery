{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "Y6_5fp7PtMCi"
      },
      "outputs": [],
      "source": [
        "# Step 1: Install required libraries\n",
        "!pip install -q langchain langchain-community langchain-google-genai google-generativeai"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q streamlit"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4H8E1p3KnbXw",
        "outputId": "5012c3f5-eeea-42fd-f8e4-b09285ad164f"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.3/44.3 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.1/9.1 MB\u001b[0m \u001b[31m84.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m116.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.1/79.1 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!npm install -q localtunnel"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GR79Rbe1nccf",
        "outputId": "70f9b0cb-a781-4703-d8ae-661919473351"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1G\u001b[0K⠙\u001b[1G\u001b[0K⠹\u001b[1G\u001b[0K⠸\u001b[1G\u001b[0K⠼\u001b[1G\u001b[0K⠴\u001b[1G\u001b[0K⠦\u001b[1G\u001b[0K⠧\u001b[1G\u001b[0K⠇\u001b[1G\u001b[0K⠏\u001b[1G\u001b[0K⠋\u001b[1G\u001b[0K⠙\u001b[1G\u001b[0K⠹\u001b[1G\u001b[0K⠸\u001b[1G\u001b[0K⠼\u001b[1G\u001b[0K⠴\u001b[1G\u001b[0K⠦\u001b[1G\u001b[0K⠧\u001b[1G\u001b[0K⠇\u001b[1G\u001b[0K⠏\u001b[1G\u001b[0K⠋\u001b[1G\u001b[0K⠙\u001b[1G\u001b[0K⠹\u001b[1G\u001b[0K\n",
            "added 22 packages in 2s\n",
            "\u001b[1G\u001b[0K⠹\u001b[1G\u001b[0K\n",
            "\u001b[1G\u001b[0K⠹\u001b[1G\u001b[0K3 packages are looking for funding\n",
            "\u001b[1G\u001b[0K⠹\u001b[1G\u001b[0K  run `npm fund` for details\n",
            "\u001b[1G\u001b[0K⠹\u001b[1G\u001b[0K"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install python-dotenv"
      ],
      "metadata": {
        "id": "_slq5F84viN5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "285dd277-598e-44dd-bf55-96210d31aa80"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: python-dotenv in /usr/local/lib/python3.11/dist-packages (1.0.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile .env\n",
        "GOOGLE_API_KEY=\"YOUR_GOOGLE_API_KEY\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8BfRJcCXAMEj",
        "outputId": "b9a4c48a-30e4-465d-cd52-9c98c16cdfb7"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing .env\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile financial_QA.py\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "from langchain_core.messages import (\n",
        "    SystemMessage,\n",
        "    HumanMessage\n",
        ")\n",
        "from dotenv import load_dotenv\n",
        "import streamlit as st\n",
        "\n",
        "load_dotenv()\n",
        "\n",
        "class FinancialAssistantChatbotCore:\n",
        "  def __init__(self, model_name) -> None:\n",
        "    self.model_name = model_name\n",
        "    self.chat_model = self.initialize_model()\n",
        "    self.parser = StrOutputParser()\n",
        "\n",
        "  def initialize_model(self):\n",
        "    return ChatGoogleGenerativeAI(model=self.model_name)\n",
        "\n",
        "  def generate_response(self, prompt):\n",
        "    messages = [\n",
        "        SystemMessage(content=\"You are an expert in financial assistance, skilled in explaining things in a simple and easy to understand\"),\n",
        "        HumanMessage(content=prompt)\n",
        "    ]\n",
        "\n",
        "    return self.chat_model.invoke(messages)\n",
        "\n",
        "  def format_response(self, response):\n",
        "    return self.parser.invoke(response)\n",
        "\n",
        "\n",
        "def initialize():\n",
        "  if \"messages\" not in st.session_state:\n",
        "    st.session_state.messages = []\n",
        "\n",
        "def display_chat_history():\n",
        "  for message in st.session_state.messages:\n",
        "    with st.chat_message(message[\"role\"]):\n",
        "      st.write(message[\"content\"])\n",
        "\n",
        "def add_message_to_history(role, message):\n",
        "  st.session_state.messages.append({\"role\": role, \"content\": message})\n",
        "\n",
        "def display_message(role, message):\n",
        "  with st.chat_message(role):\n",
        "    st.write(message)\n",
        "\n",
        "def main():\n",
        "  st.title(\"Financial Assistance ChatBot\")\n",
        "  st.write(\"This chatbot is designed to help you with financial assistance questions in a simple and easy-to-understand manner.\")\n",
        "\n",
        "  model_name = st.sidebar.selectbox(\"Select Model\", [\"gemini-1.5-pro\", \"gemini-pro\"])\n",
        "\n",
        "  chatbot_core = FinancialAssistantChatbotCore(model_name=model_name)\n",
        "\n",
        "  initialize()\n",
        "  display_chat_history()\n",
        "\n",
        "  prompt = st.chat_input(\"Enter your question...\")\n",
        "\n",
        "  if prompt:\n",
        "    add_message_to_history(\"user\", prompt)\n",
        "    display_message(\"user\", prompt)\n",
        "\n",
        "    with st.status(\"AI model response...\"):\n",
        "      response = chatbot_core.generate_response(prompt=prompt)\n",
        "      formatted_response = chatbot_core.format_response(response)\n",
        "\n",
        "      add_message_to_history(\"assistant\", formatted_response)\n",
        "      display_message(\"assistant\", formatted_response)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "  main()"
      ],
      "metadata": {
        "id": "KRNE3ImrJPwS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eb55f127-4e72-4e6c-aa29-4fbb4bebfbb0"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing financial_QA.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!streamlit run financial_QA.py &>/content/logs.txt &"
      ],
      "metadata": {
        "id": "DcNHGa4k5AiL"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!wget -q -O - ipv4.icanhazip.com"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zgQ8iWxT5NjE",
        "outputId": "383da106-4584-4087-86b4-6b50055fffff"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "34.169.74.245\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!npx localtunnel --port 8501"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TZiQFOzw5OWD",
        "outputId": "b001557c-8183-4bae-b906-cee3280e9633"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1G\u001b[0K⠙\u001b[1G\u001b[0Kyour url is: https://icy-paws-bet.loca.lt\n",
            "^C\n"
          ]
        }
      ]
    }
  ]
}